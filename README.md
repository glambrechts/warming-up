# Warming Up Recurrent Neural Networks to Maximise Reachable Multistability Greatly Improves Learning

Official implementation of the [warmup initialisation procedure](https://hdl.handle.net/2268/260699) for RNNs.

This repository contains the datasets, recurrent cells and experiments presented the paper.
See `python supervised.py -h` and `python reinforcement.py -h` for usage details.
If you find it useful, please reference in your paper:
```
@article{lambrechts2023warming,
  title={Warming up recurrent neural networks to maximise reachable multistability greatly improves learning},
  author={Lambrechts, Gaspard and De Geeter, Florent and Vecoven, Nicolas and Ernst, Damien and Drion, Guillaume},
  journal={Neural Networks},
  year={2023},
  publisher={Elsevier}
}
```

To learn more:
- [Blog post](http://blogs.ulg.ac.be/damien-ernst/warming-up-recurrent-neural-networks-to-maximise-reachable-multistability-greatly-improves-learning)
- [Research paper](https://hdl.handle.net/2268/260699)
